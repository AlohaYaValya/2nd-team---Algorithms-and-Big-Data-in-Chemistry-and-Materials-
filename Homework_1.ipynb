{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b392cb3",
   "metadata": {},
   "source": [
    "# Homework №1 - Data collecting and cleansing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c40d9d",
   "metadata": {},
   "source": [
    "## Data preparing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c016a5",
   "metadata": {},
   "source": [
    "First of all let's import all the libraries we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8e55f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-23T17:42:53.401894Z",
     "start_time": "2023-03-23T17:42:27.022736Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import requests\n",
    "import time\n",
    "from typing import List\n",
    "from tqdm import tqdm\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7803b21",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T15:32:06.082130Z",
     "start_time": "2023-03-07T15:32:05.883034Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('./data_2.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf971f2d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T15:32:07.174509Z",
     "start_time": "2023-03-07T15:32:07.137568Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55905df4",
   "metadata": {},
   "source": [
    "Let's check how many gaps we have in the lines, try to fill them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc72d77",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T15:32:10.371633Z",
     "start_time": "2023-03-07T15:32:10.359665Z"
    }
   },
   "outputs": [],
   "source": [
    "columns = list(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f868537",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T15:32:10.684095Z",
     "start_time": "2023-03-07T15:32:10.675094Z"
    }
   },
   "outputs": [],
   "source": [
    "columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c026101",
   "metadata": {},
   "source": [
    "In the inirial dataframe we have several colums leasted above.\n",
    "Let's determine what value each parameter has:\n",
    "\n",
    "1) **DOI (Digital Object Identifier)** - is a string of numbers, letters and symbols used to uniquely identify an article or document, and to provide it with a permanent web address (URL);\n",
    "\n",
    "2) **Date** - date  of article publication;\n",
    "3) **Journal** - the name of the journal in which the article was published;\n",
    "\n",
    "4) **Title** - the title of the article;\n",
    "\n",
    "5) **Name** - the systematic name, trivial name formula of the chemical compound;\n",
    "\n",
    "6) **measurement_error** -  is the difference between a measured quantity and its true value;\n",
    "\n",
    "7) **measurement_wavelength** -  important factor in the determination of refractive index using a spectrophotometer or other optical instrument;\n",
    "\n",
    "8) **measurement_method** - procedures or techniques used to make these assignments and obtain the numerical or symbolic representation of the properties or characteristics being measured;\n",
    "\n",
    "9) **normalised_name (SMILES)** - standard notation used in chemistry to represent the structure of molecules and chemical reactions using a short, linear string of characters;\n",
    "\n",
    "10) **raw_value (reflecting index)** - the measure of bending of a light ray when passing from one medium to another during the experiment;\n",
    "\n",
    "11) **specifier** - the type of raw_value value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602eae3a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T15:32:12.223406Z",
     "start_time": "2023-03-07T15:32:12.208874Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"Missing values distribution by column: \")\n",
    "print(data.isnull().mean())\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78034919",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-04T13:07:52.821262Z",
     "start_time": "2023-03-04T13:07:52.814281Z"
    }
   },
   "source": [
    "Now we can easily look at the distribution of missing values in the given dataset, for example: in the column 'measurement_wavelength' 88,58% of data is missing, in 'normalised_name' - 41,16%, which is sucks actually:( Good news: in columns 'DOI', 'measurement_error', 'measurement_method', 'raw_value' and 'specifier' there are no missing values at all! Cool!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a02b8d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T15:32:14.370856Z",
     "start_time": "2023-03-07T15:32:14.358887Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Column datatypes: \")\n",
    "print(data.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115d69b2",
   "metadata": {},
   "source": [
    "Now let's see at the type of data we have. All the columns have object as their datatype aside from 'measurement_error'. In pandas, object means either string or mixed type (numerical and non-numerical type mixed)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ec7962",
   "metadata": {},
   "source": [
    "Finally, let’s make sure we remove any trailing characters and whitespace using 'strip':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dcd1fdc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T15:32:15.445227Z",
     "start_time": "2023-03-07T15:32:15.434256Z"
    }
   },
   "outputs": [],
   "source": [
    "str_cols = list(data.columns)\n",
    "str_cols.remove('measurement_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c587d14",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T15:32:17.645200Z",
     "start_time": "2023-03-07T15:32:17.500542Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in str_cols:\n",
    "    data[i] = data[i].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547c8c44",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T15:32:17.848199Z",
     "start_time": "2023-03-07T15:32:17.829219Z"
    }
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814b7c2a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T15:32:20.558817Z",
     "start_time": "2023-03-07T15:32:20.393108Z"
    }
   },
   "outputs": [],
   "source": [
    "missing_by_row = data.isnull().sum(axis=1)\n",
    "sorted_rows = data.loc[missing_by_row.sort_values(ascending=False).index]\n",
    "print(\"Top 10 rows with the most missing values:\")\n",
    "print(sorted_rows.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c379384",
   "metadata": {},
   "source": [
    "Oops, it seems like in some cases in the column 'DOI' the Journal name sticks to the DOI, let's fix it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e59a571",
   "metadata": {},
   "source": [
    "### Fixing DOI column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05688351",
   "metadata": {},
   "source": [
    "Let's have one doi as an example and try to fix it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc36016",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T15:32:23.385479Z",
     "start_time": "2023-03-07T15:32:23.371488Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(data.loc[3056, 'DOI'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4442c49",
   "metadata": {},
   "source": [
    "Let's also convert the 'DOI' column into a list so it would be more comfy to work with ir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09182327",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T15:32:23.665990Z",
     "start_time": "2023-03-07T15:32:23.653027Z"
    }
   },
   "outputs": [],
   "source": [
    "DOI_column = data['DOI'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be047421",
   "metadata": {},
   "source": [
    "To separate the DOI from all the other unnecessary stuff we have in this column, let's use a regular expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e96f0b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T15:32:23.994665Z",
     "start_time": "2023-03-07T15:32:23.980662Z"
    }
   },
   "outputs": [],
   "source": [
    "DOI_pattern = re.compile(r'^10\\.\\d{4,9}\\/[-._;()\\/:A-Z0-9]+(?=_)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd7e456",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T15:32:24.635680Z",
     "start_time": "2023-03-07T15:32:24.617732Z"
    }
   },
   "outputs": [],
   "source": [
    "DOI_example = '10.1016/S0963-9969(01)00105-3Food Research International'\n",
    "DOI_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ab6d78",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T15:32:27.286011Z",
     "start_time": "2023-03-07T15:32:27.268575Z"
    }
   },
   "outputs": [],
   "source": [
    "DOI_match_example = re.match(DOI_pattern, DOI_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9963f0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T15:32:27.659207Z",
     "start_time": "2023-03-07T15:32:27.642256Z"
    }
   },
   "outputs": [],
   "source": [
    "DOI_match_example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cbacf2b",
   "metadata": {},
   "source": [
    "Okay, it worked. Now let's try it on the whole column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde496bb",
   "metadata": {},
   "source": [
    "For that, let's first create a function which will check if the doi valid or not "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b132449",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-14T11:58:55.505717Z",
     "start_time": "2023-03-14T11:58:55.497740Z"
    }
   },
   "outputs": [],
   "source": [
    "def is_valid_doi(doi_str:str) -> bool:\n",
    "    \"\"\"\n",
    "    Check if a DOI is valid and corresponds to an article on the internet.\n",
    "    \n",
    "    Args:\n",
    "        doi_str (str): A string representing the DOI to be checked.\n",
    "        \n",
    "    Returns:\n",
    "        bool: True if the DOI is valid and corresponds to an article with metadata available on the internet, False otherwise.\n",
    "        \n",
    "    Example Usage:\n",
    "        >>> is_valid_doi('10.1016/j.jacc.2020.02.068')\n",
    "        True\n",
    "    \"\"\"\n",
    "    # Construct the API URL for the DOI\n",
    "    url = f\"https://api.crossref.org/works/{doi_str}\"\n",
    "    \n",
    "    # Make an HTTP request to the API\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        # Extract the metadata from the response\n",
    "        metadata = response.json()[\"message\"]\n",
    "        # Check if the metadata contains a title (i.e., the DOI is valid)\n",
    "        if \"title\" in metadata:\n",
    "            return True\n",
    "    # If the request failed or the metadata does not contain a title, the DOI is invalid\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e814a0c3",
   "metadata": {},
   "source": [
    "Next let's create a function which will clean the DOI column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d29549",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-13T14:35:05.427963Z",
     "start_time": "2023-03-13T14:35:05.419002Z"
    }
   },
   "outputs": [],
   "source": [
    "def clean_DOI(initial_DOI_list: List[str]) -> List[str]:\n",
    "    \"\"\"\n",
    "    Clean a list of DOIs by removing invalid DOIs and keeping only valid DOIs with metadata available on the internet.\n",
    "\n",
    "    Args:\n",
    "        initial_DOI_list (List[str]): A list of strings representing the DOIs to be cleaned.\n",
    "\n",
    "    Returns:\n",
    "        List[str]: A list of strings representing the cleaned DOIs. Each element of the returned list is either a valid DOI or the string 'invalid' if the DOI is not valid or does not have metadata available on the internet.\n",
    "\n",
    "    Example Usage:\n",
    "        >>> clean_DOI(['10.1016/j.jacc.2020.02.068', '10.3390/bs10010012', '10.1038/nature12373', '10.1162/REST_a_00136'])\n",
    "        ['10.1016/j.jacc.2020.02.068', '10.3390/bs10010012', 'invalid', 'invalid']\n",
    "    \"\"\"\n",
    "    DOI_pattern = re.compile(r'^10\\.\\d{4,9}\\/[-._;()\\/:A-Z0-9]+', flags=re.IGNORECASE)\n",
    "    cleaned_DOI_list = []\n",
    "    for DOI in tqdm(initial_DOI_list):\n",
    "        DOI_match = re.findall(DOI_pattern, DOI)\n",
    "        if DOI_match:\n",
    "            DOI_cleaned = DOI_match[0].strip('_')\n",
    "            if is_valid_doi(DOI_cleaned):\n",
    "                cleaned_DOI_list.append(DOI_cleaned)\n",
    "            else:\n",
    "                cleaned_DOI_list.append('invalid')\n",
    "        else:\n",
    "            cleaned_DOI_list.append('invalid')\n",
    "            print(DOI)\n",
    "        # Sleep for 0.125 seconds\n",
    "        time.sleep(0.125)\n",
    "    return cleaned_DOI_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0bf779c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T16:30:25.821245Z",
     "start_time": "2023-03-07T15:41:48.659904Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "DOI_new = clean_DOI(DOI_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901fd191",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T16:55:25.080574Z",
     "start_time": "2023-03-07T16:55:25.073594Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(len(DOI_column))\n",
    "print(len(DOI_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ffcd7f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T16:55:26.804925Z",
     "start_time": "2023-03-07T16:55:26.792927Z"
    }
   },
   "outputs": [],
   "source": [
    "DOI_new.count('invalid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2a5c53",
   "metadata": {},
   "source": [
    "After all, there are still 173 invalid DOI's. Let's try to use another regular expressin on those invalid DOI's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59d439e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T16:55:30.624799Z",
     "start_time": "2023-03-07T16:55:30.602324Z"
    }
   },
   "outputs": [],
   "source": [
    "invalid_ids = [i for i, x in enumerate(DOI_new) if x == 'invalid']\n",
    "print(invalid_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e3b92b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T16:55:31.863033Z",
     "start_time": "2023-03-07T16:55:31.849558Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "invalid_elements = [DOI_column[i] for i in invalid_ids]\n",
    "print(invalid_elements, invalid_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37013d6c",
   "metadata": {},
   "source": [
    "First of all let's save our dataframe in case something will go wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab594317",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T16:55:35.161208Z",
     "start_time": "2023-03-07T16:55:34.914814Z"
    }
   },
   "outputs": [],
   "source": [
    "data.iloc[invalid_ids,:].to_csv(\"data_2_invalid.tsv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f967c0aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T16:55:35.899283Z",
     "start_time": "2023-03-07T16:55:35.887279Z"
    }
   },
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52fa0f4a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-15T11:07:17.616063Z",
     "start_time": "2023-03-15T11:07:16.675087Z"
    }
   },
   "source": [
    "New pattern will make sure the DOI ends up with digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2eca76a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T16:55:37.265290Z",
     "start_time": "2023-03-07T16:55:37.248337Z"
    }
   },
   "outputs": [],
   "source": [
    "DOI_no_invalid_elements = [re.findall(r'^10\\.\\d{4,9}\\/[-._;()\\/:A-Z0-9]+\\d', invalid_element) for invalid_element in invalid_elements]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8f6679",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T16:55:37.753042Z",
     "start_time": "2023-03-07T16:55:37.742040Z"
    }
   },
   "outputs": [],
   "source": [
    "DOI_no_invalid_elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22aadd3d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T16:56:06.923895Z",
     "start_time": "2023-03-07T16:55:39.973640Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "status_DOI = [is_valid_doi(DOI_no_invalid_element[0]) for DOI_no_invalid_element in tqdm(DOI_no_invalid_elements) if DOI_no_invalid_element]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e0c2e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T16:56:16.358785Z",
     "start_time": "2023-03-07T16:56:16.338314Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "status_DOI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7aef12e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T16:56:17.361696Z",
     "start_time": "2023-03-07T16:56:17.350729Z"
    }
   },
   "outputs": [],
   "source": [
    "DOI_pattern_2 = re.compile(r'^10\\.\\d{4,9}\\/[-._;()\\/:A-Z0-9]+\\d', flags=re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6961dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-06T12:28:31.436859Z",
     "start_time": "2023-03-06T12:28:31.418871Z"
    }
   },
   "outputs": [],
   "source": [
    "#DOI_new_backup = DOI_new.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78252846",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-06T12:28:31.980373Z",
     "start_time": "2023-03-06T12:28:31.952448Z"
    }
   },
   "outputs": [],
   "source": [
    "#with open('DOI_new_backup.txt', 'w') as DOI_file:\n",
    "    #for DOI in DOI_new_backup:\n",
    "        #DOI_file.write(DOI+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93dabf1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T16:57:39.767775Z",
     "start_time": "2023-03-07T16:56:23.661698Z"
    }
   },
   "outputs": [],
   "source": [
    "yet_invalid_DOI = {}\n",
    "for id_x,DOI in tqdm(enumerate(DOI_new)):\n",
    "    if DOI == 'invalid':\n",
    "        DOI_to_cor = DOI_column[id_x]\n",
    "        DOI_pot_cor = re.findall(DOI_pattern_2, DOI_to_cor)\n",
    "        if len(DOI_pot_cor)>0:\n",
    "            if is_valid_doi(DOI_pot_cor[0]):\n",
    "                DOI_new[id_x] = DOI_pot_cor[0]\n",
    "            else:\n",
    "                yet_invalid_DOI[id_x]=DOI_to_cor\n",
    "        else:\n",
    "            yet_invalid_DOI[id_x]=DOI_to_cor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9ee65e",
   "metadata": {},
   "source": [
    "We have yet still invalid DOI, let's take a look at them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8bad3b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T16:57:41.310336Z",
     "start_time": "2023-03-07T16:57:41.290393Z"
    }
   },
   "outputs": [],
   "source": [
    "yet_invalid_DOI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2919c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T16:57:42.219210Z",
     "start_time": "2023-03-07T16:57:42.198260Z"
    }
   },
   "outputs": [],
   "source": [
    "len(DOI_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21abece9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T16:57:43.991488Z",
     "start_time": "2023-03-07T16:57:43.972540Z"
    }
   },
   "outputs": [],
   "source": [
    "DOI_new.count('invalid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caca1096",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-06T12:30:23.985430Z",
     "start_time": "2023-03-06T12:30:23.965494Z"
    }
   },
   "outputs": [],
   "source": [
    "#DOI_new = DOI_new_backup.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1aeda7a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T16:57:47.141650Z",
     "start_time": "2023-03-07T16:57:47.124670Z"
    }
   },
   "outputs": [],
   "source": [
    "yet_invalid_DOI = {114: '10.1038/ncomms8',\n",
    " 136: '10.1016/j.mee.2004.03.068Microelectronic Engineering',\n",
    " 2057: '10.1016/S0026-2692(03)00137-XMicroelectronics Journal',\n",
    " 2790: '10.1016/j.snb.2004.06.015',\n",
    " 3095: '10.1016/S1350-4495(99)00047-XInfrared Physics & Technology',\n",
    " 3178: '10.3389/fpls.2014.00',\n",
    " 3555: '10.1002/jbio.201700',\n",
    " 4420: '10.1016/S0925-4005(99)00427-XSensors and Actuators B: Chemical',\n",
    " 4500: '10.1063/1.4765',\n",
    " 4681: '10.1016/S0038-092X(00)00013-XSolar Energy'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f751c42",
   "metadata": {},
   "source": [
    "There are only 10 of them, so let's check em and append manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c88f2f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T16:57:49.171839Z",
     "start_time": "2023-03-07T16:57:49.162859Z"
    }
   },
   "outputs": [],
   "source": [
    "DOI_new[114] = 'NA'\n",
    "DOI_new[136] = '10.1016/j.mee.2004.03.068'\n",
    "DOI_new[2057] = '10.1016/S0026-2692(03)00137-X'\n",
    "DOI_new[2790] = '10.1016/j.snb.2004.06.015'\n",
    "DOI_new[3095] = '10.1016/S1350-4495(99)00047-X'\n",
    "DOI_new[3178] = 'NA'\n",
    "DOI_new[3555] = 'NA'\n",
    "DOI_new[4420] = '10.1016/S0925-4005(99)00427-X'\n",
    "DOI_new[4500] = 'NA'\n",
    "DOI_new[4681] = '10.1016/S0038-092X(00)00013-X'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ecd2c6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T16:57:51.055513Z",
     "start_time": "2023-03-07T16:57:51.039589Z"
    }
   },
   "outputs": [],
   "source": [
    "data['DOI'] = DOI_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70f8d81",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T16:57:51.652087Z",
     "start_time": "2023-03-07T16:57:51.595239Z"
    }
   },
   "outputs": [],
   "source": [
    "data.to_csv('data_2_DOI_new.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf69836",
   "metadata": {},
   "source": [
    "## Getting missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1b8a0f",
   "metadata": {},
   "source": [
    "Let's think on how to collect missing values from columns 'Date', 'Journal', 'Title'. We can use that parsing information about the papers in json format through the crossref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52819476",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T16:58:06.463033Z",
     "start_time": "2023-03-07T16:57:52.833026Z"
    }
   },
   "outputs": [],
   "source": [
    "pip install crossref-commons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77784451",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T16:58:53.346579Z",
     "start_time": "2023-03-07T16:58:53.071890Z"
    }
   },
   "outputs": [],
   "source": [
    "import crossref_commons.retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b962c5",
   "metadata": {},
   "source": [
    "Let's make a query using doi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e190f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T16:58:54.397975Z",
     "start_time": "2023-03-07T16:58:53.970836Z"
    }
   },
   "outputs": [],
   "source": [
    "tmp = crossref_commons.retrieval.get_publication_as_json('10.1016/j.jallcom.2017.03.270')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae13eb9",
   "metadata": {},
   "source": [
    "Here we can see key-words, using them we can identify which values we need to collect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d923ba04",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T16:58:56.553789Z",
     "start_time": "2023-03-07T16:58:56.540791Z"
    }
   },
   "outputs": [],
   "source": [
    "for key,value in tmp.items():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486e837f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T16:58:59.121860Z",
     "start_time": "2023-03-07T16:58:59.100919Z"
    }
   },
   "outputs": [],
   "source": [
    "tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fef5515",
   "metadata": {},
   "source": [
    "Collecting date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04d6d69",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T16:58:59.498854Z",
     "start_time": "2023-03-07T16:58:59.487969Z"
    }
   },
   "outputs": [],
   "source": [
    "tmp['indexed']['date-parts'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10ca5a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T16:59:01.727331Z",
     "start_time": "2023-03-07T16:59:01.712374Z"
    }
   },
   "outputs": [],
   "source": [
    "publish_date = f\"{tmp['indexed']['date-parts'][0][1]}/{tmp['indexed']['date-parts'][0][2]}/{tmp['indexed']['date-parts'][0][0]}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825b5806",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T16:59:02.057916Z",
     "start_time": "2023-03-07T16:59:02.038964Z"
    }
   },
   "outputs": [],
   "source": [
    "publish_date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a4d4cb",
   "metadata": {},
   "source": [
    "Collecting Title of the article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70acf82f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T16:59:02.324331Z",
     "start_time": "2023-03-07T16:59:02.316353Z"
    }
   },
   "outputs": [],
   "source": [
    "article_title = tmp['title'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0aeeba6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T16:59:02.669030Z",
     "start_time": "2023-03-07T16:59:02.646564Z"
    }
   },
   "outputs": [],
   "source": [
    "article_title"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8da21b8",
   "metadata": {},
   "source": [
    "Collecting the name of the journal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add86aa5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T16:59:03.257957Z",
     "start_time": "2023-03-07T16:59:03.247943Z"
    }
   },
   "outputs": [],
   "source": [
    "print(tmp['short-container-title'])\n",
    "print(tmp['container-title'])\n",
    "print(tmp['original-title'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6acf925",
   "metadata": {},
   "source": [
    "Here we can see that few key-words could the the name of the journal, They are kinda the same, so we'll sellect the first one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc49bcd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T16:59:05.213254Z",
     "start_time": "2023-03-07T16:59:05.204246Z"
    }
   },
   "outputs": [],
   "source": [
    "journal_title = tmp['short-container-title'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46e7cda",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T16:59:05.335308Z",
     "start_time": "2023-03-07T16:59:05.335308Z"
    }
   },
   "outputs": [],
   "source": [
    "journal_title"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0bfbba",
   "metadata": {},
   "source": [
    "### Getting rid of rows with missing DOI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5fb204",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T16:59:05.701361Z",
     "start_time": "2023-03-07T16:59:05.605585Z"
    }
   },
   "outputs": [],
   "source": [
    "#Let's count how many rows have incorrect DOIs:\n",
    "data['DOI'].value_counts()['NA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf22a21",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T16:59:08.332923Z",
     "start_time": "2023-03-07T16:59:08.234023Z"
    }
   },
   "outputs": [],
   "source": [
    "data = data.drop(data[data['DOI'] == 'NA'].index)\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d460a8",
   "metadata": {},
   "source": [
    "### Getting rid of duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fef6194",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T16:59:16.015974Z",
     "start_time": "2023-03-07T16:59:15.821623Z"
    }
   },
   "outputs": [],
   "source": [
    "#let's check if there are any duplicates in the df:\n",
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d01cca3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T16:59:17.052054Z",
     "start_time": "2023-03-07T16:59:17.030104Z"
    }
   },
   "outputs": [],
   "source": [
    "duplicates = data[data.duplicated(keep=False)]\n",
    "print(duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9108ba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T16:59:18.117263Z",
     "start_time": "2023-03-07T16:59:18.104304Z"
    }
   },
   "outputs": [],
   "source": [
    "unique_data = data.drop_duplicates()\n",
    "len(unique_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37c7c75",
   "metadata": {},
   "source": [
    "### Filling in title, journal names and date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13932d46",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T16:59:24.691090Z",
     "start_time": "2023-03-07T16:59:24.677097Z"
    }
   },
   "outputs": [],
   "source": [
    "#to do: сделать функцию\n",
    "#проверка1: АПИ вернуло что-то (лен тмп больше 0)\n",
    "#проверка2: indexed, title, short-container-title ЕСТЬ -> (try (выполнить) exept ('NA'))\n",
    "#сделать словарь: ключ - DOI, значения - лист(indexed, title, short-container-title) -> pandas.df -> примёрджить к нашей data по DOI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd920317",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Missing values distribution by column: \")\n",
    "print(unique_data.isnull().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f2b898",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T16:59:28.443415Z",
     "start_time": "2023-03-07T16:59:28.424434Z"
    }
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30d3aba",
   "metadata": {},
   "source": [
    "Here we can see, that the most missing data we have is in the columns 'measurement_wavelength', 'normalised_name', but we'll fill them a bit later here. Firstly let's look at the other column - 'Title'. For some reason the name of the articles were imported not as the sentances but as the continuous sequence of large letters. Also there is missing values in the 'Date' and 'Journal' columns which we should also fill in. Now when we know that all the rows are unique and valid, let's collect this data from the articles with the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf08061b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T16:59:59.359725Z",
     "start_time": "2023-03-07T16:59:59.296863Z"
    }
   },
   "outputs": [],
   "source": [
    "unique_data.to_csv('data_copy.csv', sep=',', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d446f774",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T17:00:20.097178Z",
     "start_time": "2023-03-07T17:00:20.073242Z"
    }
   },
   "outputs": [],
   "source": [
    "def fill_date_journal_title(data):\n",
    "    result = {}\n",
    "    for row in tqdm(data):\n",
    "        doi, date, journal, title = row\n",
    "        if not is_valid_doi(doi):\n",
    "            result[doi] = [date, journal, title]\n",
    "            continue\n",
    "        tmp = crossref_commons.retrieval.get_publication_as_json(doi)\n",
    "        if len(tmp) == 0:\n",
    "            result[doi] = [date, journal, title]\n",
    "            continue\n",
    "        try:\n",
    "            date_parts = tmp['indexed']['date-parts'][0]\n",
    "            if date_parts:\n",
    "                date = f\"{date_parts[1]}/{date_parts[2]}/{date_parts[0]}\"\n",
    "        except (KeyError, TypeError, IndexError):\n",
    "            pass\n",
    "        try:\n",
    "            title = tmp['title'][0]\n",
    "        except (KeyError, TypeError, IndexError):\n",
    "            pass\n",
    "        try:\n",
    "            journal = tmp['short-container-title'][0]\n",
    "        except (KeyError, TypeError, IndexError):\n",
    "            pass\n",
    "        result[doi] = [date, journal, title]\n",
    "        \n",
    "        time.sleep(0.125) # Sleep for 0.125 seconds fro not to be banned by API\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e074289",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T17:00:22.958118Z",
     "start_time": "2023-03-07T17:00:22.891266Z"
    }
   },
   "outputs": [],
   "source": [
    "unique_data.to_csv('unique_data.csv', index=False, sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7e6680",
   "metadata": {},
   "source": [
    "Now let's apply the function to the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f6a6cb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T18:23:48.022448Z",
     "start_time": "2023-03-07T17:00:33.556321Z"
    }
   },
   "outputs": [],
   "source": [
    "data_list = unique_data[['DOI', 'Date', 'Journal', 'Title']].values.tolist()\n",
    "data_filled = fill_date_journal_title(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62407a70",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T21:20:45.632203Z",
     "start_time": "2023-03-07T21:20:45.619206Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Missing values distribution by column: \")\n",
    "print(unique_data.isnull().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62399aea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T21:20:50.669914Z",
     "start_time": "2023-03-07T21:20:50.364778Z"
    }
   },
   "outputs": [],
   "source": [
    "data_filled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1310d0a",
   "metadata": {},
   "source": [
    "### Filling in SMILES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b5bf6e",
   "metadata": {},
   "source": [
    "Now let's fill in missing smiles using PubChem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45862272",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-13T20:59:16.208562Z",
     "start_time": "2023-03-13T20:16:13.150284Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set up the PubChem API URL and parameters\n",
    "url = \"https://pubchem.ncbi.nlm.nih.gov/rest/pug/compound/name/\"\n",
    "params = {\"property\": \"CanonicalSMILES\"}\n",
    "\n",
    "# Create an empty list to store the SMILES\n",
    "smiles = []\n",
    "\n",
    "# Loop through each compound name and get the SMILES from the PubChem API\n",
    "for name in tqdm(data_filled[\"Name\"]):\n",
    "    try:\n",
    "        # Make a request to the PubChem API and extract the SMILES\n",
    "        response = requests.get(url + name + \"/property/\" + params[\"property\"] + \"/JSON\")\n",
    "        response_json = response.json()\n",
    "        smile = response_json[\"PropertyTable\"][\"Properties\"][0][\"CanonicalSMILES\"]\n",
    "        smiles.append(smile)\n",
    "    except:\n",
    "        # If there is an error, append a NaN value to the list\n",
    "        smiles.append(None)\n",
    "\n",
    "# Add the SMILES to the data frame\n",
    "data_filled[\"SMILES\"] = smiles\n",
    "\n",
    "# Save the updated data frame to a new CSV file\n",
    "data_filled.to_csv(\"data_with_smiles.tsv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86edc8e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-14T12:53:07.546706Z",
     "start_time": "2023-03-14T12:53:07.234795Z"
    }
   },
   "outputs": [],
   "source": [
    "data_filled = pd.read_csv('data_with_smiles.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6098d0",
   "metadata": {},
   "source": [
    "Filling missing smiles in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070e817e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-14T12:53:23.686992Z",
     "start_time": "2023-03-14T12:53:23.673998Z"
    }
   },
   "outputs": [],
   "source": [
    "data_filled[\"normalised_name\"].fillna(data_filled[\"SMILES\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0897229",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-14T12:55:53.638183Z",
     "start_time": "2023-03-14T12:55:53.561358Z"
    }
   },
   "outputs": [],
   "source": [
    "data_filled.to_csv(\"data_filled_.tsv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f9836d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-13T21:27:11.207712Z",
     "start_time": "2023-03-13T21:27:09.250418Z"
    }
   },
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "for index, row in tqdm(data_filled.iterrows()):\n",
    "    # check if normalised_name is missing a value\n",
    "    if pd.isna(row[\"normalised_name\"]):\n",
    "        # generate a SMILES string from the Name column\n",
    "        mol = Chem.MolFromSmiles(row[\"Name\"])\n",
    "        if mol is not None:\n",
    "            smiles = Chem.MolToSmiles(mol)\n",
    "            # update the normalised_name column with the SMILES string\n",
    "            data_filled.at[index, \"normalised_name\"] = smiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45621e3f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-14T12:33:01.369971Z",
     "start_time": "2023-03-14T12:33:01.341066Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Missing values distribution by column: \")\n",
    "print(data_filled.isnull().mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d04017",
   "metadata": {},
   "source": [
    "Can see that some smiles are still missing, let's try another way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb54196f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-14T12:33:11.761619Z",
     "start_time": "2023-03-14T12:33:11.681849Z"
    }
   },
   "outputs": [],
   "source": [
    "data_filled.to_csv(\"data_filled.tsv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e070edf9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-13T22:13:38.547575Z",
     "start_time": "2023-03-13T22:12:51.124748Z"
    }
   },
   "outputs": [],
   "source": [
    "from chemspipy import ChemSpider\n",
    "\n",
    "# initialize the ChemSpider API client\n",
    "cs = ChemSpider(\"YOUR_API_KEY\")\n",
    "\n",
    "# iterate over the rows in the DataFrame\n",
    "for index, row in tqdm(data_filled.iterrows()):\n",
    "    # check if the normalised_name is missing a value\n",
    "    if pd.isna(row[\"normalised_name\"]):\n",
    "        # get the name of the compound\n",
    "        name = row[\"Name\"]\n",
    "        # search for the compound in ChemSpider\n",
    "        results = cs.search(name)\n",
    "        # check if any results were found\n",
    "        if len(results) > 0:\n",
    "            # get the SMILES string of the first result\n",
    "            smiles = results[0].smiles\n",
    "            # update the normalised_name column with the SMILES string\n",
    "            data_filled.at[index, \"normalised_name\"] = smiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5152a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-14T12:33:59.376720Z",
     "start_time": "2023-03-14T12:33:59.354812Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"Missing values distribution by column: \")\n",
    "print(data_filled.isnull().mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43fbf288",
   "metadata": {},
   "source": [
    "Saving the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8edcf3da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-14T13:06:18.270450Z",
     "start_time": "2023-03-14T13:06:18.188637Z"
    }
   },
   "outputs": [],
   "source": [
    "data_filled.to_csv('data_KONECHNOE.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ebc0ef",
   "metadata": {},
   "source": [
    "### Fixing raw values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0182a529",
   "metadata": {},
   "source": [
    "First of all, let's create a regular expression to describe the pattern of this parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9827a612",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-14T13:09:56.287941Z",
     "start_time": "2023-03-14T13:09:56.272953Z"
    }
   },
   "outputs": [],
   "source": [
    "raw_value_pattern = r'^\\d+(\\.\\d+)?$'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6a37fe",
   "metadata": {},
   "source": [
    "Then, let's check what pattern of the column matches this pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e933b91e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-14T13:14:00.590323Z",
     "start_time": "2023-03-14T13:14:00.478049Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Calculate the percentage of values that match the pattern\n",
    "matches = data_filled['raw_value'].str.match(raw_value_pattern).sum()\n",
    "total = len(data_filled['raw_value'])\n",
    "match_percent = 100 * matches / total\n",
    "print(f\"Percentage of values that match the pattern: {match_percent:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb9688b",
   "metadata": {},
   "source": [
    "All the values which do not match the pattern we put together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87bff39b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-14T13:14:46.611671Z",
     "start_time": "2023-03-14T13:14:46.593688Z"
    }
   },
   "outputs": [],
   "source": [
    "non_matches = data_filled[~data_filled['raw_value'].str.match(raw_value_pattern)]['raw_value']\n",
    "print(\"Values that do not match the pattern:\")\n",
    "print(non_matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf05010e",
   "metadata": {},
   "source": [
    "In order to correct incorrect values ​​that do not satisfy the pattern, we find all possible patterns and group them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9b4219",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-14T16:36:46.317382Z",
     "start_time": "2023-03-14T16:36:45.001636Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import difflib\n",
    "\n",
    "# Define a function to find the closest match to a string in a list\n",
    "def find_closest_match(string, string_list):\n",
    "    matches = difflib.get_close_matches(string, string_list, n=1, cutoff=0.8)\n",
    "    if matches:\n",
    "        return matches[0]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Define a function to get the pattern for a given value\n",
    "def get_pattern(value, pattern_groups):\n",
    "    pattern = re.sub(r'\\d+(\\.\\d+)?', r'X', value)\n",
    "    match = find_closest_match(pattern, pattern_groups.keys())\n",
    "    if match:\n",
    "        return match\n",
    "    else:\n",
    "        return pattern\n",
    "\n",
    "# Group the values by pattern similarity\n",
    "pattern_groups = {}\n",
    "for value in data_filled['raw_value']:\n",
    "    pattern = get_pattern(value, pattern_groups)\n",
    "    if pattern in pattern_groups:\n",
    "        pattern_groups[pattern].append(value)\n",
    "    else:\n",
    "        pattern_groups[pattern] = [value]\n",
    "\n",
    "# Create a new column with the patterns\n",
    "data_filled['patterns'] = data_filled['raw_value'].apply(get_pattern, args=(pattern_groups,))\n",
    "\n",
    "# Print out the groups\n",
    "for pattern, values in pattern_groups.items():\n",
    "    print(f\"Pattern {pattern}:\")\n",
    "    print(values)\n",
    "\n",
    "# Print out the patterns\n",
    "print(f\"Patterns: {list(pattern_groups.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be0a7a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-14T16:37:22.459908Z",
     "start_time": "2023-03-14T16:37:21.226570Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_filled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58fa2a99",
   "metadata": {},
   "source": [
    "As the result i have a list of patterns:\n",
    "['X', 'X±X', 'X []', 'X–X', 'X to X', 'X−X', 'X ± X', 'X ± X', 'X (X)', '∼X', '~X', 'X ± X', 'X-X', 'X, X, X', 'X + iX', 'X (EtOH)', 'X, X', 'X +', 'X,X ± X,X', 'X at X μm', '<X', 'X–X (this)', 'X X X X', 'X*', 'X+Xi', 'X; X; X', 'Xe']\n",
    "I want you to write a code for each pattern:\n",
    "- If the pattern is the 'X', remains the original value\n",
    "- if the pattern is the 'X±X', remains the first X, the X after '±' deleats\n",
    "- if the pattern is the 'X []', remains the X, the ' []' delleats\n",
    "- if the pattern is the 'X–X', the mean of two X before and after '–' should be found\n",
    "- if the pattern is the 'X to X', the the mean of two X before and after ' to ' should be found\n",
    "- if the pattern is the 'X−X', the mean of two X before and after '−' should be found\n",
    "- if the pattern is the 'X ± X', remains the first X, the X after ' ± ' should be deleated\n",
    "- if the pattern is the 'X ± X', remains the first X, the X after ' ± ' should be deleated\n",
    "- if the pattern is the 'X (X)', the '(' and ')' should be deleated\n",
    "- if the pattern is the '∼X', remains the X, the '∼' should be deleated\n",
    "- if the pattern is the '~X', remains the X, the '~' should be deleated\n",
    "- if the pattern is the 'X ± X', remains the first X, the X after ' ± ' should be deleated\n",
    "- if the pattern is the 'X-X', the mean of two X before and after '-' should be found\n",
    "- if the pattern is the 'X, X, X', the mean of three X should be found\n",
    "- if the pattern is the 'X + iX', remains the first X, the X after ' + ' should be deleated\n",
    "- if the pattern is the 'X (EtOH)', remain the X, ' (EtOH)' should be deleated\n",
    "- if the pattern is the 'X, X', the mean of two X before and after ', ' should be found\n",
    "- if the pattern is the 'X +', remain the X, ' +' should be deleated\n",
    "- if the pattern is the 'X,X ± X,X', the ',' should be replaced with '.', and then everything after '±' should be deleated\n",
    "- if the pattern is the 'X at X μm', remain the first X, ' at X μm' should be deleated\n",
    "- if the pattern is the '<X', remain the X, '<' should be deleated\n",
    "- if the pattern is the 'X–X (this)', the the mean of two X before and after '–' should be found, ' (this)' should be deleated\n",
    "- if the pattern is the 'X X X X', the the mean of four X should be found\n",
    "- if the pattern is the 'X*', remain the X, '*' should be deleated\n",
    "- if the pattern is the 'X+Xi', the the mean of two X before and after '+' should be found, 'i' should be deleated\n",
    "- if the pattern is the 'X; X; X', the the mean of three X should be found\n",
    "- if the pattern is the 'Xe', remain the X, 'e' should be deleated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a68115d",
   "metadata": {},
   "source": [
    "Let's make a function which will fix all those wrong patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780ad556",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-14T16:38:25.902825Z",
     "start_time": "2023-03-14T16:38:25.815301Z"
    }
   },
   "outputs": [],
   "source": [
    "def process_value(value, pattern):\n",
    "    if not value:\n",
    "        return None\n",
    "    if pattern == 'X':\n",
    "        return value\n",
    "    elif pattern == 'X±X':\n",
    "        return value.split('±')[0]\n",
    "    elif pattern == 'X []':\n",
    "        return value.split(' [')[0]\n",
    "    elif pattern == 'X–X' or pattern == 'X to X' or pattern == 'X−X' or pattern == 'X-X':\n",
    "        values = re.findall('\\d+(\\.\\d+)?', value)\n",
    "        return str(np.mean([float(v) for v in values if v.strip() != '']))\n",
    "    elif pattern == 'X ± X' or pattern == 'X ± X':\n",
    "        return value.split('±')[0].split('±')[0]\n",
    "    elif pattern == 'X (X)':\n",
    "        return value.split('(')[0].split(')')[0]\n",
    "    elif pattern == '∼X' or pattern == '~X':\n",
    "        return value.split('∼')[0].split('~')[0]\n",
    "    elif pattern == 'X, X, X' or pattern == 'X, X' or pattern == 'X,X ± X,X':\n",
    "        values = re.findall('\\d+(\\.\\d+)?', value)\n",
    "        return str(np.mean([float(v) for v in values if v.strip() != '']))\n",
    "    elif pattern == 'X + iX' or pattern == 'X+Xi':\n",
    "        return value.split(' +')[0]\n",
    "    elif pattern == 'X (EtOH)':\n",
    "        return value.split(' (')[0]\n",
    "    elif pattern == 'X at X μm':\n",
    "        return value.split(' at ')[0]\n",
    "    elif '<' in value and pattern == '<X':\n",
    "        return float(value.split('<')[1])\n",
    "    elif pattern == 'X–X (this)':\n",
    "        values = re.findall('\\d+(\\.\\d+)?', value)\n",
    "        return str(np.mean([float(v) for v in values if v.strip() != '']))\n",
    "    elif pattern == 'X X X X':\n",
    "        values = re.findall('\\d+(\\.\\d+)?', value)\n",
    "        return str(np.mean([float(v) for v in values if v.strip() != '']))\n",
    "    elif pattern == 'X*':\n",
    "        return value.split('*')[0]\n",
    "    elif pattern == 'X +':\n",
    "        return value.split(' +')[0]\n",
    "    elif pattern == 'X; X; X':\n",
    "        values = re.findall('\\d+(\\.\\d+)?', value)\n",
    "        return str(np.mean([float(v) for v in values if v.strip() != '']))\n",
    "    elif pattern == 'Xe':\n",
    "        return value.split('e')[0]\n",
    "    else:\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f5f3c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-14T16:38:29.834218Z",
     "start_time": "2023-03-14T16:38:29.829234Z"
    }
   },
   "outputs": [],
   "source": [
    "patterns = list(data_filled['patterns'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72044842",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-14T17:02:55.807764Z",
     "start_time": "2023-03-14T17:02:49.308163Z"
    }
   },
   "outputs": [],
   "source": [
    "values = list(data_filled['raw_value'])\n",
    "import pandas as pd\n",
    "\n",
    "# create a DataFrame from the list\n",
    "df = pd.DataFrame({'values': values})\n",
    "\n",
    "# save the DataFrame to an Excel file\n",
    "df.to_excel('values.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ece6cf9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-14T20:47:44.665068Z",
     "start_time": "2023-03-14T20:47:44.442660Z"
    }
   },
   "outputs": [],
   "source": [
    "data.to_csv('data_final.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8269423",
   "metadata": {},
   "source": [
    "### Collecting CIDs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea103bc6",
   "metadata": {},
   "source": [
    "CID stands for Chemical Identifier. It is a unique identifier assigned to chemical substances to facilitate their identification and tracking. We can collect some information using it later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a0584e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-15T09:47:26.766785Z",
     "start_time": "2023-03-15T09:47:23.006089Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('./data_final.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9249838",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-16T01:06:59.365759Z",
     "start_time": "2023-03-16T00:01:57.161621Z"
    }
   },
   "outputs": [],
   "source": [
    "import pubchempy as pcp\n",
    "\n",
    "# Define a function to get the CID for a given SMILES string\n",
    "def get_cid(smiles):\n",
    "    try:\n",
    "        # Search PubChem database using the SMILES string\n",
    "        results = pcp.get_compounds(smiles, 'smiles')\n",
    "        if len(results) > 0:\n",
    "            # Return the CID number of the first result\n",
    "            return results[0].cid\n",
    "    except:\n",
    "        pass\n",
    "    return None\n",
    "\n",
    "# Apply the get_cid function to the 'normalized_name' column and store the results in a new column called 'CID'\n",
    "data['CID'] = data['normalised_name'].apply(get_cid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672680ea",
   "metadata": {},
   "source": [
    "Let's drop all the rows where CID and SMILES are missing, we couldn't find descriptors for them anyways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836ac68f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-16T07:53:23.341178Z",
     "start_time": "2023-03-16T07:53:23.102295Z"
    }
   },
   "outputs": [],
   "source": [
    "filtered_df = df[df['normalised_name'].isna() & df['CID'].isna()]\n",
    "filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0f497c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-16T08:58:04.702300Z",
     "start_time": "2023-03-16T08:58:04.683315Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['normalised_name', 'CID'], how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1b3646",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-16T10:18:58.179742Z",
     "start_time": "2023-03-16T10:18:56.945186Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel('final_dataset.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f51e462",
   "metadata": {},
   "source": [
    "## Getting descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31dd355d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-22T05:35:33.243220Z",
     "start_time": "2023-03-22T05:35:31.999438Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel('final_dataset.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e39852e",
   "metadata": {},
   "source": [
    "### RDKit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1965c16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pubchempy as pcp\n",
    "from rdkit import Chem\n",
    "from mordred import Calculator, descriptors\n",
    "from rdkit.Chem import Descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81469f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "calc = Calculator(descriptors, ignore_3D=True)\n",
    "len(calc.descriptors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6775f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_descriptors(smiles):\n",
    "    try:\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        result = calc(mol)\n",
    "        return result\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99adf14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('final_dataset.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb82ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to calculate RDKit descriptors for a given SMILES string\n",
    "def calc_descriptors(smiles):\n",
    "    if isinstance(smiles, float):\n",
    "        # return a dictionary with NaN values for missing or invalid SMILES strings\n",
    "        desc_dict = {}\n",
    "        for desc_name, desc_func in Descriptors.descList:\n",
    "            desc_dict[desc_name] = np.nan\n",
    "        return desc_dict\n",
    "    # convert the SMILES string to an RDKit molecule object\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is None:\n",
    "        # return a dictionary with NaN values for invalid molecules\n",
    "        desc_dict = {}\n",
    "        for desc_name, desc_func in Descriptors.descList:\n",
    "            desc_dict[desc_name] = np.nan\n",
    "        return desc_dict\n",
    "    # calculate a dictionary of all available RDKit descriptors for the molecule\n",
    "    desc_dict = {}\n",
    "    for desc_name, desc_func in Descriptors.descList:\n",
    "        desc_dict[desc_name] = desc_func(mol)\n",
    "    return desc_dict\n",
    "\n",
    "# drop any rows with missing values in the 'normalised_name' column\n",
    "df = df.dropna(subset=['normalised_name'])\n",
    "\n",
    "# calculate RDKit descriptors for each compound in the 'normalised_name' column\n",
    "df.loc[:, 'rdkit_desc'] = df['normalised_name'].apply(calc_descriptors)\n",
    "\n",
    "# convert the resulting dictionary of descriptors to separate columns in the DataFrame\n",
    "df = pd.concat([df, pd.DataFrame.from_dict(df['rdkit_desc'].tolist())], axis=1)\n",
    "\n",
    "# drop the original 'rdkit_desc' column since it's no longer needed\n",
    "df = df.drop(columns=['rdkit_desc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568f7c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(\"df_after_rdkit.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975e16b7",
   "metadata": {},
   "source": [
    "### Mordred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a340cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit.Chem import AllChem\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Descriptors\n",
    "from rdkit.ML.Descriptors import MoleculeDescriptors\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from mordred import Calculator, descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d54a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install session_info\n",
    "import session_info\n",
    "session_info.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503d9243",
   "metadata": {},
   "outputs": [],
   "source": [
    "def All_Mordred_descriptors(data):\n",
    "    calc = Calculator(descriptors, ignore_3D=False)\n",
    "    mols = []\n",
    "    for smi in data:\n",
    "        if isinstance(smi, float):\n",
    "            # skip missing or invalid SMILES strings\n",
    "            mols.append(None)\n",
    "        else:\n",
    "            mols.append(Chem.MolFromSmiles(smi))\n",
    "\n",
    "    # remove any molecules that failed to convert from SMILES\n",
    "    mols = [mol for mol in mols if mol is not None]\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    descriptors_df = calc.pandas(mols)\n",
    "\n",
    "    # add the descriptor columns to the original dataframe\n",
    "    for column in descriptors_df.columns:\n",
    "        df[column] = descriptors_df[column]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f557eaa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create descriptor calculator with all descriptors\n",
    "calc = Calculator(descriptors, ignore_3D=True)\n",
    "\n",
    "len(calc.descriptors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96621f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# call the function with the input dataframe to get the dataframe with new columns\n",
    "mordred_descriptors = All_Mordred_descriptors(df['normalised_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4334eeeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "mordred_descriptors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493c81de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat = pd.concat([df, mordred_descriptors.drop(columns=['normalised_name'])], axis=1)  # Concatenate the dataframes horizontally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd867d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat.to_csv('df_after_mordred.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0104f2ac",
   "metadata": {},
   "source": [
    "### PubChem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d118e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-23T17:48:19.168722Z",
     "start_time": "2023-03-23T17:48:19.062975Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df.rename(columns={'CID': 'cid'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345cef9d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-23T17:48:25.866226Z",
     "start_time": "2023-03-23T17:48:25.744527Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df.rename(columns={'normalised_name': 'isomeric_smiles'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c2616f",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-03-23T12:27:39.686Z"
    }
   },
   "outputs": [],
   "source": [
    "# create an empty list to store the descriptors\n",
    "descriptors = []\n",
    "\n",
    "# iterate over the CID column in the dataframe\n",
    "for i, cid in tqdm(df['cid'].items()):\n",
    "    \n",
    "    # check if the value is missing or not\n",
    "    if pd.isna(cid):\n",
    "        descriptors.append({'xlogp': None, 'tpsa': None, 'exact_mass': None, 'molecular_weight': None, 'complexity': None, 'index': i})\n",
    "    else:\n",
    "        try:\n",
    "            # convert float value to integer\n",
    "            cid = int(cid)\n",
    "            \n",
    "            # search for the compound using the CID\n",
    "            compound = pcp.Compound.from_cid(cid)\n",
    "\n",
    "            # extract the descriptors and add them to the list\n",
    "            descriptors.append(compound.to_dict(properties=['xlogp', 'tpsa', 'exact_mass', 'molecular_weight', 'complexity']) | {'index': i})\n",
    "\n",
    "            # add a delay between requests to avoid exceeding rate limit\n",
    "            time.sleep(0.3)\n",
    "        except (ValueError, pcp.PubChemHTTPError):\n",
    "            # if there's an error, add missing descriptors and the index to the list\n",
    "            descriptors.append({'xlogp': None, 'tpsa': None, 'exact_mass': None, 'molecular_weight': None, 'complexity': None, 'index': i})\n",
    "    \n",
    "# create a new dataframe with the descriptors\n",
    "df_descriptors = pd.DataFrame(descriptors)\n",
    "\n",
    "# set the index of df_descriptors to the 'index' column\n",
    "df_descriptors.set_index('index', inplace=True)\n",
    "\n",
    "# merge the two dataframes by index\n",
    "df = df.merge(df_descriptors, left_index=True, right_index=True)\n",
    "\n",
    "df.to_csv('df_all_descriptors.tsv', sep='\\t', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "960px",
    "left": "24.9922px",
    "top": "135.855px",
    "width": "322.715px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
